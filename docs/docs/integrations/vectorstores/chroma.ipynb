{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "683953b3",
   "metadata": {},
   "source": [
    "# Chroma\n",
    "\n",
    "This notebook covers how to get started with the `Chroma` vector store.\n",
    "\n",
    ">[Chroma](https://docs.trychroma.com/getting-started) is a AI-native open-source vector database focused on developer productivity and happiness. Chroma is licensed under Apache 2.0. View the full docs of `Chroma` at [this page](https://docs.trychroma.com/reference/py-collection), and find the API reference for the LangChain integration at [this page](https://python.langchain.com/v0.2/api_reference/chroma/vectorstores/langchain_chroma.vectorstores.Chroma.html).\n",
    "\n",
    "## Setup\n",
    "\n",
    "To access `Chroma` vector stores you'll need to install the `langchain-chroma` integration package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83a43688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "botocore 1.31.58 requires jmespath<2.0.0,>=0.7.1, which is not installed.\n",
      "parlai 1.7.2 requires datasets<2.2.2,>=1.4.1, which is not installed.\n",
      "parlai 1.7.2 requires GitPython, which is not installed.\n",
      "parlai 1.7.2 requires google-api-core<=2.11.0, which is not installed.\n",
      "parlai 1.7.2 requires joblib, which is not installed.\n",
      "parlai 1.7.2 requires markdown<=3.3.2, which is not installed.\n",
      "parlai 1.7.2 requires nltk, which is not installed.\n",
      "parlai 1.7.2 requires scikit-learn, which is not installed.\n",
      "parlai 1.7.2 requires scipy, which is not installed.\n",
      "prefect 2.18.0 requires asyncpg>=0.23, which is not installed.\n",
      "twine 4.0.2 requires requests-toolbelt!=0.9.0,>=0.8.0, which is not installed.\n",
      "unstructured 0.10.27 requires chardet, which is not installed.\n",
      "unstructured 0.10.27 requires lxml, which is not installed.\n",
      "unstructured 0.10.27 requires nltk, which is not installed.\n",
      "unstructured 0.10.27 requires rapidfuzz, which is not installed.\n",
      "unstructured-inference 0.7.10 requires opencv-python!=4.7.0.68, which is not installed.\n",
      "unstructured-inference 0.7.10 requires rapidfuzz, which is not installed.\n",
      "jupyter-ai 1.0.0 requires importlib-metadata~=5.2.0, but you have importlib-metadata 6.11.0 which is incompatible.\n",
      "jupyter-ai 1.0.0 requires jupyterlab<4,>=3.5, but you have jupyterlab 4.2.4 which is incompatible.\n",
      "jupyter-ai 1.0.0 requires langchain==0.0.220, but you have langchain 0.2.13 which is incompatible.\n",
      "jupyter-ai 1.0.0 requires openai~=0.26, but you have openai 1.40.6 which is incompatible.\n",
      "jupyter-ai 1.0.0 requires typing-extensions==4.5.0, but you have typing-extensions 4.12.2 which is incompatible.\n",
      "jupyter-ai-magics 2.0.1 requires importlib-metadata~=5.2.0, but you have importlib-metadata 6.11.0 which is incompatible.\n",
      "jupyter-ai-magics 2.0.1 requires langchain==0.0.220, but you have langchain 0.2.13 which is incompatible.\n",
      "jupyter-ai-magics 2.0.1 requires typing-extensions==4.5.0, but you have typing-extensions 4.12.2 which is incompatible.\n",
      "parlai 1.7.2 requires attrs~=20.2.0, but you have attrs 24.2.0 which is incompatible.\n",
      "parlai 1.7.2 requires docutils<0.16,>=0.14, but you have docutils 0.17.1 which is incompatible.\n",
      "parlai 1.7.2 requires fsspec~=2022.2.0, but you have fsspec 2023.12.2 which is incompatible.\n",
      "parlai 1.7.2 requires numpy~=1.23.0, but you have numpy 1.26.4 which is incompatible.\n",
      "parlai 1.7.2 requires protobuf<=3.20.3,>=3.8.0, but you have protobuf 4.24.2 which is incompatible.\n",
      "parlai 1.7.2 requires Sphinx~=5.1.0, but you have sphinx 4.5.0 which is incompatible.\n",
      "parlai 1.7.2 requires tqdm~=4.62.1, but you have tqdm 4.66.5 which is incompatible.\n",
      "prefect 2.18.0 requires anyio<4.0.0,>=3.7.1, but you have anyio 4.4.0 which is incompatible.\n",
      "prefect 2.18.0 requires uvicorn<0.29.0,>=0.14.0, but you have uvicorn 0.30.1 which is incompatible.\n",
      "spacy 3.7.2 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
      "tweepy 4.14.0 requires requests-oauthlib<2,>=1.2.0, but you have requests-oauthlib 2.0.0 which is incompatible.\n",
      "types-requests 2.32.0.20240602 requires urllib3>=2, but you have urllib3 1.26.20 which is incompatible.\n",
      "unstructured-inference 0.7.10 requires onnxruntime<1.16, but you have onnxruntime 1.18.0 which is incompatible.\n",
      "weasel 0.3.3 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
      "weaviate-client 3.22.1 requires requests<=2.31.0,>=2.28.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU \"langchain-chroma>=0.1.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5ffbf8",
   "metadata": {},
   "source": [
    "### Credentials\n",
    "\n",
    "You can use the `Chroma` vector store without any credentials, simply installing the package above is enough!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd17cfed",
   "metadata": {},
   "source": [
    "If you want to get best in-class automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e1243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47f73f4",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "### Basic Initialization \n",
    "\n",
    "Below is a basic initialization, including the use of a directory to save the data locally.\n",
    "\n",
    "```{=mdx}\n",
    "import EmbeddingTabs from \"@theme/EmbeddingTabs\";\n",
    "\n",
    "<EmbeddingTabs/>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3ed0a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ea11a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not neccesary\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb62a8c",
   "metadata": {},
   "source": [
    "### Initialization from client\n",
    "\n",
    "You can also initialize from a `Chroma` client, which is particularly useful if you want easier access to the underlying database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fe4457f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrisonchase/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 79.3M/79.3M [00:16<00:00, 4.89MiB/s]\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "persistent_client = chromadb.PersistentClient()\n",
    "collection = persistent_client.get_or_create_collection(\"collection_name\")\n",
    "collection.add(ids=[\"1\", \"2\", \"3\"], documents=[\"a\", \"b\", \"c\"])\n",
    "\n",
    "vector_store_from_client = Chroma(\n",
    "    client=persistent_client,\n",
    "    collection_name=\"collection_name\",\n",
    "    embedding_function=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d037340",
   "metadata": {},
   "source": [
    "## Manage vector store\n",
    "\n",
    "Once you have created your vector store, we can interact with it by adding and deleting different items.\n",
    "\n",
    "### Add items to vector store\n",
    "\n",
    "We can add items to our vector store by using the `add_documents` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da279339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['7efce43b-e806-42a8-9be6-9b70b3b1c587',\n",
       " '321c89c0-c055-434d-a37a-b2a4197e25d8',\n",
       " '94dd7f41-76ce-4b0c-ad43-f5ccf2ade4bc',\n",
       " '55edf47c-1a95-4597-8962-a2ac02973f34',\n",
       " 'fe47c5e1-622e-4fca-9398-6800db4a2919',\n",
       " '74033a4c-9c88-4d11-9914-5b4d0570ea5a',\n",
       " 'f0db2c5a-6da5-4856-9d6e-e1348ef5a620',\n",
       " 'd0b51368-10f1-4ffc-8329-e5c60b9e6252',\n",
       " '0de7df2b-f1f3-4260-9fb8-f97c2f089958',\n",
       " '3d7b0776-e459-4a76-8c70-00e87a5caa0c']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=1,\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=2,\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=3,\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=4,\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=5,\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    "    id=6,\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    "    id=7,\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=8,\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=9,\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=10,\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7add6366",
   "metadata": {},
   "source": [
    "### Update items in vector store\n",
    "\n",
    "Now that we have added documents to our vector store, we can update existing documents by using the `update_documents` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef5dbd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_document_1 = Document(\n",
    "    page_content=\"I had chocalate chip pancakes and fried eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=1,\n",
    ")\n",
    "\n",
    "updated_document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is sunny and warm, with a high of 82 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=2,\n",
    ")\n",
    "\n",
    "vector_store.update_document(document_id=uuids[0], document=updated_document_1)\n",
    "# You can also update multiple documents at once\n",
    "vector_store.update_documents(\n",
    "    ids=uuids[:2], documents=[updated_document_1, updated_document_1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b9a13a",
   "metadata": {},
   "source": [
    "### Delete items from vector store\n",
    "\n",
    "We can also delete items from our vector store as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56f17791",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.delete(ids=uuids[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213acf08",
   "metadata": {},
   "source": [
    "## Query vector store\n",
    "\n",
    "Once your vector store has been created and the relevant documents have been added you will most likely wish to query it during the running of your chain or agent. \n",
    "\n",
    "### Query directly\n",
    "\n",
    "#### Similarity search\n",
    "\n",
    "Performing a simple similarity search can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebfcda95-8fdc-4e1d-93c1-d39e6be2ed97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!'),\n",
       " Document(metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building stateful, agentic applications!'),\n",
       " Document(metadata={'source': 'tweet'}, page_content='I had chocalate chip pancakes and scrambled eggs for breakfast this morning.'),\n",
       " Document(metadata={'source': 'website'}, page_content='The top 10 soccer players in the world right now.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "vector_store.as_retriever().invoke(\"LangChain provides abstractions to make working with LLMs easy\",\n",
    "    k=2,\n",
    "    filter={\"source\": \"tweet\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2b96fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n",
      "* LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
    "    k=2,\n",
    "    filter={\"source\": \"tweet\"},\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd117ea",
   "metadata": {},
   "source": [
    "#### Similarity search with score\n",
    "\n",
    "If you want to execute a similarity search and receive the corresponding scores you can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2768a331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=1.726390] The stock market is down 500 points today due to fears of a recession. [{'source': 'news'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    \"Will it be hot tomorrow?\", k=1, filter={\"source\": \"news\"}\n",
    ")\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b436c8",
   "metadata": {},
   "source": [
    "#### Search by vector\n",
    "\n",
    "You can also search by vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ea434a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* I had chocalate chip pancakes and fried eggs for breakfast this morning. [{'source': 'tweet'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search_by_vector(\n",
    "    embedding=embeddings.embed_query(\"I love green eggs and ham!\"), k=1\n",
    ")\n",
    "for doc in results:\n",
    "    print(f\"* {doc.page_content} [{doc.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1c1e6f",
   "metadata": {},
   "source": [
    "#### Other search methods\n",
    "\n",
    "There are a variety of other search methods that are not covered in this notebook, such as MMR search or searching by vector. For a full list of the search abilities available for `AstraDBVectorStore` check out the [API reference](https://python.langchain.com/v0.2/api_reference/astradb/vectorstores/langchain_astradb.vectorstores.AstraDBVectorStore.html).\n",
    "\n",
    "### Query by turning into retriever\n",
    "\n",
    "You can also transform the vector store into a retriever for easier usage in your chains. For more information on the different search types and kwargs you can pass, please visit the API reference [here](https://python.langchain.com/v0.2/api_reference/chroma/vectorstores/langchain_chroma.vectorstores.Chroma.html#langchain_chroma.vectorstores.Chroma.as_retriever)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b6f7867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 1, \"fetch_k\": 5}\n",
    ")\n",
    "retriever.invoke(\"Stealing from the bank is a crime\", filter={\"source\": \"news\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b7b73c",
   "metadata": {},
   "source": [
    "## Usage for retrieval-augmented generation\n",
    "\n",
    "For guides on how to use this vector store for retrieval-augmented generation (RAG), see the following sections:\n",
    "\n",
    "- [Tutorials: working with external knowledge](https://python.langchain.com/v0.2/docs/tutorials/#working-with-external-knowledge)\n",
    "- [How-to: Question and answer with RAG](https://python.langchain.com/v0.2/docs/how_to/#qa-with-rag)\n",
    "- [Retrieval conceptual docs](https://python.langchain.com/v0.2/docs/concepts/#retrieval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed28359",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all `Chroma` vector store features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/chroma/vectorstores/langchain_chroma.vectorstores.Chroma.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
